Train:
  seed: 0
  epochs: 100
  batch_size: 64
  svae_iterations: 4
  discriminator_iterations: 2
  init_budget_frac: 0.10  # Fraction of samples that AL starts with
  budget_frac: 0.10 # Fraction of data to sample at each AL iteration
  cycle_frac: 0.05 # Fraction of data to test AL cycle with
  # data_splits: [0.1, 0.2, 0.5, 1.0]
  max_runs: 3       # Number of complete cycles to perform of AL
  al_mode: 'svaal'  # Type of AL to perform (options: svaal, random)
  es_patience: 10  # Rounds until early stopping
  lr_sched_factor: 0.5  # Factor to reduce LR by at each schedule cycle
  lr_patience: 2 # Rounds until reducing LR 
Models:
  TaskLearner:
    Parameters: {
      'embedding_dim': 767, # Currently need to change to have tl_ prefix if running experiments
      'hidden_dim': 583,     # Currently need to change to have tl_ prefix if running experiments
      'rnn_type': 'gru'
    }
    learning_rate: 0.072875
  Discriminator:
    Parameters: {
      'z_dim': 64,
      'fc_dim': 128
    }
    learning_rate: 0.0005 # same as VAAL
  SVAE:
    # Model parameters
    Parameters:
      {'embedding_dim': 256,
      'hidden_dim': 256,
      'rnn_type': 'gru',
      'num_layers': 1,
      'bidirectional': False,
      'latent_size': 64,
      'word_dropout': 0.0,
      'embedding_dropout': 0.5}
    learning_rate: 0.0005
    # Aux function parameters
    anneal_function: 'logistic'
    k: 0.0025   # 0.05 
    x0: 2500    # 250
    adversarial_hyperparameter: 1

Utils:
  task_type: SEQ
  special_token2idx: {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}
  SEQ:
    data_name:  bbn  # conll2003 ontonotes-5.0
    # If no data_split then set to False
    data_split: ['train', 'valid', 'test']
    data_root_path: /home/tyler/Desktop/Repos/s-vaal/data/SEQ/bbn # conll2003 ontonotes-5.0
    # Minimum occurence of tokens in corpus
    min_occurence: 0
    max_sequence_length: 59
  CLF:
    data_name: ag_news
    data_split: ['train', 'test']
    data_root_path: /home/tyler/Desktop/Repos/s-vaal/data/CLF/ag_news
    min_occurence: 0
    # Does max sequence length need to be max length - no special tokens e.g. 20 - 2 (SOS, EOS) = 18
    max_sequence_length: 18
  tb_write_freq: 50   # Frequency to write to tensorboard (batches)

Data:
  # All data specified here is pre-processed and encoded as vectors with special tokens as those specified in Utils
  # conll2003: /home/tyler/Desktop/Repos/s-vaal/data/SEQ/conll2003/conll2003.json
  # conll2003_vocab: /home/tyler/Desktop/Repos/s-vaal/data/conll2003/conll2003_vocabs.json
  # ag_news: /home/tyler/Desktop/Repos/s-vaal/data/ag_news/ag_news.json
  # ag_news_vocab: /home/tyler/Desktop/Repos/s-vaal/data/ag_news/ag_news_vocabs.json