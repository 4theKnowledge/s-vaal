Model:
  output_classes: ['ORG', 'PER', 'LOC', 'MISC']
  max_sequence_length: 10
  TaskLearner:
    Parameters: {
      'embedding_dim': 64,
      'hidden_dim': 64
    }
    learning_rate: 0.01
  Discriminator:
    # currently not using z_dim from config in model
    z_dim: 16
    learning_rate: 0.0005 # same as VAAL
  SVAE:
    # Model parameters
    # 'batch_size': 16,
    Parameters:
      {'embedding_size': 64,
      'hidden_size': 64,
      'rnn_type': 'gru',
      'num_layers': 1,
      'bidirectional': False,
      'latent_size': 16,
      'word_dropout': 0,
      'embedding_dropout': 0.5}
    learning_rate: 0.001
    # Aux function parameters
    anneal_function: 'logistic'
    k: 0.0025
    x0: 2500
Utils:
  seed: 0
  task_type: NER
  special_token2idx: {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}
  NER:
    data_name: conll2003
    # If no data_split then set to False
    data_split: ['train', 'test', 'valid']
    data_root_path: /home/tyler/Desktop/Repos/s-vaal/data/conll2003
    # Minimum occurence of tokens in corpus
    min_occurence: 5
    max_sequence_length: 20
  CLF:
    data_name: ag_news
    data_split: ['train', 'test']
    data_root_path: /home/tyler/Desktop/Repos/s-vaal/data/ag_news
    min_occurence: 5
    # Does max sequence length need to be max length - no special tokens e.g. 20 - 2 (SOS, EOS) = 18
    max_sequence_length: 18
Data:
  # All data specified here is pre-processed and encoded as vectors with special tokens as those specified in Utils
  conll2003: /home/tyler/Desktop/Repos/s-vaal/data/conll2003/conll2003.json
  conll2003_vocab: /home/tyler/Desktop/Repos/s-vaal/data/conll2003/conll2003_vocabs.json
  ag_news: /home/tyler/Desktop/Repos/s-vaal/data/ag_news/ag_news.json
  ag_news_vocab: /home/tyler/Desktop/Repos/s-vaal/data/ag_news/ag_news_vocabs.json
Train:
  epochs: 2000
  batch_size: 64
  svae_iterations: 20
  discriminator_iterations: 2
  learning_rates:
    task_learner: 0.01
    svae: 0.001
    discriminator: 0.001
  adversarial_hyperparameter: 1

Sampler:

Tester:
  batch_size: 64
  max_sequence_length: 10
  epochs: 5
  # Iterations are particularly for SVAE and Discriminator components
  iterations: 5
  # task_learner, discriminator, svae
  model_type: svae
