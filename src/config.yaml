Train:
  seed: 0
  epochs: 100
  batch_size: 18
  svae_iterations: 4
  discriminator_iterations: 2
  init_budget_frac: 0.10  # Fraction of samples that AL starts with
  budget_frac: 0.10 # Fraction of data to sample at each AL iteration
  # data_splits: [0.1, 0.2, 0.5, 1.0]
  max_runs: 3       # Number of complete cycles to perform of AL
  al_mode: 'random'  # Type of AL to perform (options: svaal, random)
  es_patience: 10  # Rounds until early stopping
  lr_sched_factor: 0.5  # Factor to reduce LR by at each schedule cycle
  lr_patience: 2 # Rounds until reducing LR 

Models:
  TaskLearner:
    Parameters: {
      'embedding_dim': 330, # Currently need to change to have tl_ prefix if running experiments
      'hidden_dim': 727     # Currently need to change to have tl_ prefix if running experiments
    }
    learning_rate: 0.08599
  Discriminator:
    # currently not using z_dim from config in model
    z_dim: 64
    learning_rate: 0.0005 # same as VAAL
  SVAE:
    # Model parameters
    Parameters:
      {'embedding_dim': 512,
      'hidden_dim': 512,
      'rnn_type': 'gru',
      'num_layers': 1,
      'bidirectional': False,
      'latent_size': 64,
      'word_dropout': 0.14,
      'embedding_dropout': 0.5}
    learning_rate: 0.001
    # Aux function parameters
    anneal_function: 'logistic'
    k: 0.0025   # 0.05 
    x0: 2500    # 250
    adversarial_hyperparameter: 1

Utils:
  task_type: SEQ
  special_token2idx: {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}
  SEQ:
    data_name: bbn #ontonotes-5.0
    # If no data_split then set to False
    data_split: ['train', 'valid', 'test']
    data_root_path: /home/tyler/Desktop/Repos/s-vaal/data/SEQ/bbn #ontonotes-5.0
    # Minimum occurence of tokens in corpus
    min_occurence: 0
    max_sequence_length: 59
  CLF:
    data_name: ag_news
    data_split: ['train', 'test']
    data_root_path: /home/tyler/Desktop/Repos/s-vaal/data/CLF/ag_news
    min_occurence: 0
    # Does max sequence length need to be max length - no special tokens e.g. 20 - 2 (SOS, EOS) = 18
    max_sequence_length: 18

Data:
  # All data specified here is pre-processed and encoded as vectors with special tokens as those specified in Utils
  # conll2003: /home/tyler/Desktop/Repos/s-vaal/data/SEQ/conll2003/conll2003.json
  # conll2003_vocab: /home/tyler/Desktop/Repos/s-vaal/data/conll2003/conll2003_vocabs.json
  # ag_news: /home/tyler/Desktop/Repos/s-vaal/data/ag_news/ag_news.json
  # ag_news_vocab: /home/tyler/Desktop/Repos/s-vaal/data/ag_news/ag_news_vocabs.json