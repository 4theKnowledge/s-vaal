{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence VAE - Scratch Pad\n",
    "The intention of this notebook is to gain further insight into SVAE code by deconstructing it into toy examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as npa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean operation in feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = np.array([10,4,2])\n",
    "sos_idx = 4\n",
    "pad_idx = 2\n",
    "prob = np.random.rand(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prob [0.75977105 0.42633342 0.41226127]\n",
      "Transformed prob [0.75977105 1.         1.        ]\n",
      "sos_idx component [ 6  0 -2]\n",
      "pad_idx component [8 2 0]\n",
      "both idx components [48  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial prob {prob}')\n",
    "prob[(sent - sos_idx) * (sent - pad_idx) == 0] = 1\n",
    "print(f'Transformed prob {prob}')\n",
    "print(f'sos_idx component {(sent-sos_idx)}')\n",
    "print(f'pad_idx component {(sent-pad_idx)}')\n",
    "print(f'both idx components {(sent - sos_idx) * (sent - pad_idx)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Sampling\n",
    "Within inference method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tensor = torch.randn(size=(10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample(dist, mode='greedy'):\n",
    "    \"\"\" \n",
    "    Greedy sampling algorithm: Greedily returns argmax of tensor based on logits\n",
    "    \"\"\"\n",
    "    print(f'Input sequence:\\n {dist}')\n",
    "    if mode == 'greedy':\n",
    "        _, sample = torch.topk(dist, 1, dim=-1)\n",
    "    sample = sample.reshape(-1)\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:\n",
      " tensor([[ 2.0437, -0.5916, -0.4880],\n",
      "        [-2.3485,  0.9154,  0.6385],\n",
      "        [-1.4997, -0.4523, -0.5832],\n",
      "        [-0.1924, -0.0612,  0.4816],\n",
      "        [-1.1067,  0.4307,  0.3938],\n",
      "        [ 0.0085,  0.5797, -1.1317],\n",
      "        [-0.5217, -0.0906,  0.0614],\n",
      "        [ 0.2188,  0.1192,  1.7752],\n",
      "        [ 1.4321, -0.5962, -0.2752],\n",
      "        [-0.1405, -0.2477, -1.0266]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 2, 1, 1, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sample(rand_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kullback-Liebler Annealing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_anneal_function(anneal_function, step, k, x0):\n",
    "    \"\"\" Anneals KL term at training time \n",
    "    \n",
    "    Bowman et al. 2016\n",
    "    \"\"\"\n",
    "    if anneal_function == 'logistic':\n",
    "        return float(1/(1+np.exp(-k*(step-x0))))\n",
    "    \n",
    "    elif anneal_function == 'linear':\n",
    "        return min(1, step/x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL annealing factor: 0\n",
      "KL annealing factor: 0.0\n",
      "KL annealing factor: 1\n",
      "KL annealing factor: 1\n",
      "KL annealing factor: 1\n",
      "KL annealing factor: 1\n",
      "KL annealing factor: 1\n",
      "KL annealing factor: 1\n",
      "KL annealing factor: 1\n",
      "KL annealing factor: 1\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for step in range(10):\n",
    "    print(f'KL annealing factor: {k}')\n",
    "    k = kl_anneal_function(\"linear\", step, k, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
